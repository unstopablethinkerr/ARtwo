<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Mobile Object Detection</title>
  <style>
    /* Basic reset */
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    body {
      background: #222;
      display: flex;
      justify-content: center;
      align-items: center;
      min-height: 100vh;
      overflow: hidden;
    }
    /* Container for the canvas */
    .camera-container {
      position: relative;
      width: 100%;
      max-width: 640px; /* maximum width for larger screens */
    }
    /* Hide the video element */
    #video {
      display: none;
    }
    /* Responsive canvas */
    #canvas {
      width: 100%;
      height: auto;
      display: block;
    }
  </style>
</head>
<body>
  <div class="camera-container">
    <!-- Video element (hidden) for the camera feed -->
    <video id="video" autoplay muted playsinline></video>
    <!-- Canvas element for drawing bounding boxes -->
    <canvas id="canvas"></canvas>
  </div>

  <!-- TensorFlow.js and the COCO-SSD model -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    let model;

    // Setup the camera with constraints to use the back camera
    async function setupCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: { ideal: "environment" },
            width: { ideal: 640 },
            height: { ideal: 480 }
          },
          audio: false
        });
        video.srcObject = stream;

        // Ensure the video metadata is loaded before proceeding
        return new Promise((resolve) => {
          video.onloadedmetadata = () => {
            // Set the canvas dimensions to match the video
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            resolve(video);
          };
        });
      } catch (err) {
        alert("Error accessing the camera: " + err);
      }
    }

    // Load the COCO-SSD model
    async function loadModel() {
      model = await cocoSsd.load();
      console.log("COCO-SSD model loaded.");
      detectFrame();
    }

    // Continuously detect objects on each frame
    function detectFrame() {
      model.detect(video).then(predictions => {
        renderPredictions(predictions);
        requestAnimationFrame(detectFrame);
      });
    }

    // Draw the predictions (bounding boxes and labels) on the canvas
    function renderPredictions(predictions) {
      // Clear previous drawings
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // Draw the current video frame as background
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // Draw each prediction
      predictions.forEach(prediction => {
        const [x, y, width, height] = prediction.bbox;
        
        // Draw bounding box
        ctx.lineWidth = 2;
        ctx.strokeStyle = "#00FFFF";
        ctx.strokeRect(x, y, width, height);

        // Draw label background for better visibility
        ctx.font = "16px Arial";
        const text = `${prediction.class} (${(prediction.score * 100).toFixed(1)}%)`;
        const textWidth = ctx.measureText(text).width;
        const textHeight = 16;
        ctx.fillStyle = "#00FFFF";
        ctx.fillRect(x, y - textHeight, textWidth + 4, textHeight);

        // Draw text (label)
        ctx.fillStyle = "#000";
        ctx.fillText(text, x + 2, y - 2);
      });
    }

    // Initialize the camera and load the model
    setupCamera().then(() => {
      video.play();
      loadModel();
    });
  </script>
</body>
</html>
